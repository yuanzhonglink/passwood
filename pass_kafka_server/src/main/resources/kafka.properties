kafka.servers=127.0.0.1:9092
kafka.topic=test
# 指定了如何将key和value序列化成二进制码流的方式
kafka.key.serializer=org.apache.kafka.common.serialization.StringSerializer
kafka.value.serializer=org.apache.kafka.common.serialization.StringSerializer
# 应答机制:
#  设置为all,表示生产者会等待所有副本成功写入该消息;
#  这种方式是最安全的，能够保证消息不丢失，但是延迟也是最大的;
kafka.acks=all
# 标示消息发送失败,生产者可以自动重试,但是此刻设置为0标示不重试;
# 这个参数需要结合retry.backoff.ms(重试等待间隔)来使用;
# 建议总的重试时间比集群重新选举群首的时间长,这样可以避免生产者过早结束重试导致失败;
kafka.retries=0
# 标示生产者为每个分区维护了一个未发送记录的缓冲区,这个缓冲区的大小由batch.size配置指定;
# 配置的很大可能会导致更多的批处理，也需要更多的内存(但是对于每个活动分区，我们通常都有一个这样的缓冲区),默认是16384Bytes;
kafka.batch.size=16384
# 指定生产者在发送批量消息前等待的时间,当设置此参数后,即便没有达到批量消息的指定大小,到达时间后生产者也会发送批量消息到broker;
# 默认情况下,生产者的发送消息线程只要空闲了就会发送消息,即便只有一条消息;
# 设置这个参数后,发送线程会等待一定的时间,这样可以批量发送消息增加吞吐量,但同时也会增加延迟;
kafka.linger.ms=1
# producer可以用来缓存数据的内存大小
kafka.buffer.memory=33554432
# 默认情况下消息是不压缩的，这个参数可以指定使用消息压缩，参数可以取值为snappy、gzip或者lz4;
kafka.compresstion.type=snappy
# 是否自动提交，默认为true。
kafka.enable.auto.commit=true
#  从poll(拉)的回话处理时长
kafka.auto.commit.interval.ms=1000
# 超时时间
kafka.session.timeout.ms=30000
# 一次最大拉取的条数
kafka.max.poll.records=1000
# 消费规则，默认earliest
kafka.auto.offset.reset=earliest